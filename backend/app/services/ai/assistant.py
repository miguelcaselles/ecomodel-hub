"""
AI Assistant for Pharmacoeconomic Analysis
Asistente de IA para anÃ¡lisis farmacoeconÃ³micos

Proporciona:
- InterpretaciÃ³n de resultados en lenguaje natural
- GuÃ­a para configuraciÃ³n de modelos
- GeneraciÃ³n de resÃºmenes ejecutivos
- Respuestas a preguntas sobre anÃ¡lisis
- Recomendaciones basadas en mejores prÃ¡cticas HTA
"""

import os
import json
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from enum import Enum
import httpx
from abc import ABC, abstractmethod


class LLMProvider(str, Enum):
    """Proveedores de LLM soportados"""
    OPENAI = "openai"
    ANTHROPIC = "anthropic"
    LOCAL = "local"  # Para modelos locales (Ollama, etc.)


@dataclass
class AssistantConfig:
    """ConfiguraciÃ³n del asistente"""
    provider: LLMProvider = LLMProvider.OPENAI
    model: str = "gpt-4o-mini"  # Modelo por defecto (econÃ³mico y rÃ¡pido)
    api_key: Optional[str] = None
    temperature: float = 0.3  # Bajo para respuestas mÃ¡s consistentes
    max_tokens: int = 2000
    language: str = "es"  # EspaÃ±ol por defecto


class BaseLLMClient(ABC):
    """Clase base para clientes LLM"""

    @abstractmethod
    async def complete(self, messages: List[Dict], **kwargs) -> str:
        pass


class OpenAIClient(BaseLLMClient):
    """Cliente para OpenAI API"""

    def __init__(self, config: AssistantConfig):
        self.config = config
        self.api_key = config.api_key or os.getenv("OPENAI_API_KEY")
        self.base_url = "https://api.openai.com/v1/chat/completions"

    async def complete(self, messages: List[Dict], **kwargs) -> str:
        if not self.api_key:
            return self._fallback_response(messages)

        async with httpx.AsyncClient() as client:
            try:
                response = await client.post(
                    self.base_url,
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": kwargs.get("model", self.config.model),
                        "messages": messages,
                        "temperature": kwargs.get("temperature", self.config.temperature),
                        "max_tokens": kwargs.get("max_tokens", self.config.max_tokens)
                    },
                    timeout=30.0
                )
                response.raise_for_status()
                data = response.json()
                return data["choices"][0]["message"]["content"]
            except Exception as e:
                return self._fallback_response(messages, str(e))

    def _fallback_response(self, messages: List[Dict], error: str = None) -> str:
        """Respuesta de fallback cuando no hay API disponible"""
        return PharmacoeconomicsExpert.generate_offline_response(messages, error)


class AnthropicClient(BaseLLMClient):
    """Cliente para Anthropic API (Claude)"""

    def __init__(self, config: AssistantConfig):
        self.config = config
        self.api_key = config.api_key or os.getenv("ANTHROPIC_API_KEY")
        self.base_url = "https://api.anthropic.com/v1/messages"

    async def complete(self, messages: List[Dict], **kwargs) -> str:
        if not self.api_key:
            return PharmacoeconomicsExpert.generate_offline_response(messages)

        # Convertir formato OpenAI a Anthropic
        system_msg = next((m["content"] for m in messages if m["role"] == "system"), "")
        conversation = [m for m in messages if m["role"] != "system"]

        async with httpx.AsyncClient() as client:
            try:
                response = await client.post(
                    self.base_url,
                    headers={
                        "x-api-key": self.api_key,
                        "Content-Type": "application/json",
                        "anthropic-version": "2023-06-01"
                    },
                    json={
                        "model": kwargs.get("model", "claude-3-haiku-20240307"),
                        "system": system_msg,
                        "messages": conversation,
                        "max_tokens": kwargs.get("max_tokens", self.config.max_tokens)
                    },
                    timeout=30.0
                )
                response.raise_for_status()
                data = response.json()
                return data["content"][0]["text"]
            except Exception:
                return PharmacoeconomicsExpert.generate_offline_response(messages)


class PharmacoeconomicsExpert:
    """
    Experto en farmacoeconomÃ­a basado en reglas
    Funciona sin conexiÃ³n a LLM externo
    """

    SYSTEM_PROMPT = """Eres un experto en farmacoeconomÃ­a y evaluaciÃ³n de tecnologÃ­as sanitarias (HTA).
Tu rol es ayudar a usuarios a:
1. Interpretar resultados de anÃ¡lisis coste-efectividad
2. Configurar modelos econÃ³micos correctamente
3. Entender conceptos como ICER, QALY, PSA, BIA
4. Cumplir con requisitos de agencias HTA (NICE, AEMPS, etc.)

Responde siempre en espaÃ±ol de forma clara y accesible.
Usa ejemplos concretos cuando sea posible.
Si detectas valores inusuales, advierte al usuario."""

    # Base de conocimiento para respuestas offline
    KNOWLEDGE_BASE = {
        "icer": {
            "definition": "El ICER (Incremental Cost-Effectiveness Ratio) representa el coste adicional por cada unidad adicional de efectividad (generalmente QALY) ganada con el nuevo tratamiento.",
            "interpretation": {
                "negative_cost_positive_effect": "Dominante: el nuevo tratamiento es mÃ¡s barato Y mÃ¡s efectivo. DecisiÃ³n clara a favor.",
                "positive_cost_positive_effect": "Cuadrante NE: mÃ¡s caro pero mÃ¡s efectivo. Comparar ICER con umbral de disponibilidad a pagar.",
                "positive_cost_negative_effect": "Dominado: mÃ¡s caro Y menos efectivo. No recomendable.",
                "negative_cost_negative_effect": "Cuadrante SW: mÃ¡s barato pero menos efectivo. DecisiÃ³n depende del trade-off aceptable."
            },
            "thresholds": {
                "spain": "20,000-30,000 â‚¬/QALY (AEMPS)",
                "uk": "20,000-30,000 Â£/QALY (NICE)",
                "who": "1-3x PIB per cÃ¡pita"
            }
        },
        "qaly": {
            "definition": "QALY (Quality-Adjusted Life Year) combina cantidad y calidad de vida. 1 QALY = 1 aÃ±o de vida en perfecta salud.",
            "range": "0 (muerte) a 1 (salud perfecta). Valores negativos posibles para estados peores que muerte."
        },
        "psa": {
            "definition": "El PSA (Probabilistic Sensitivity Analysis) evalÃºa la incertidumbre del modelo mediante simulaciones Monte Carlo.",
            "interpretation": "Genera miles de escenarios variando parÃ¡metros segÃºn sus distribuciones de probabilidad.",
            "outputs": ["Scatter plot en plano coste-efectividad", "CEAC (curva de aceptabilidad)", "Intervalos de confianza"]
        },
        "bia": {
            "definition": "El BIA (Budget Impact Analysis) estima el impacto financiero de introducir un nuevo tratamiento en el sistema sanitario.",
            "time_horizon": "TÃ­picamente 3-5 aÃ±os",
            "perspective": "Generalmente perspectiva del pagador (SNS)"
        }
    }

    @classmethod
    def generate_offline_response(cls, messages: List[Dict], error: str = None) -> str:
        """Genera respuesta sin LLM externo usando base de conocimiento"""
        user_msg = next((m["content"] for m in reversed(messages) if m["role"] == "user"), "")
        user_msg_lower = user_msg.lower()

        # Detectar intenciÃ³n
        if any(word in user_msg_lower for word in ["icer", "coste-efectividad", "incremental"]):
            return cls._explain_icer(user_msg_lower)
        elif any(word in user_msg_lower for word in ["qaly", "avac", "utilidad"]):
            return cls._explain_qaly()
        elif any(word in user_msg_lower for word in ["psa", "probabilÃ­stico", "monte carlo"]):
            return cls._explain_psa()
        elif any(word in user_msg_lower for word in ["bia", "impacto presupuestario", "budget"]):
            return cls._explain_bia()
        elif any(word in user_msg_lower for word in ["resultado", "interpretar", "significa"]):
            return cls._interpret_results_generic()
        elif any(word in user_msg_lower for word in ["configur", "parÃ¡metro", "cÃ³mo"]):
            return cls._configuration_guide()
        else:
            return cls._general_help(error)

    @classmethod
    def _explain_icer(cls, context: str) -> str:
        kb = cls.KNOWLEDGE_BASE["icer"]
        response = f"""## ICER (Ratio Coste-Efectividad Incremental)

**DefiniciÃ³n:** {kb['definition']}

**FÃ³rmula:** ICER = (Coste_nuevo - Coste_comparador) / (Efectividad_nuevo - Efectividad_comparador)

### InterpretaciÃ³n segÃºn cuadrante:

| SituaciÃ³n | InterpretaciÃ³n |
|-----------|----------------|
| MÃ¡s barato + MÃ¡s efectivo | âœ… **Dominante** - DecisiÃ³n clara |
| MÃ¡s caro + MÃ¡s efectivo | âš–ï¸ Comparar con umbral WTP |
| MÃ¡s caro + Menos efectivo | âŒ **Dominado** - No recomendable |
| MÃ¡s barato + Menos efectivo | ğŸ”„ Trade-off a evaluar |

### Umbrales de referencia:
- **EspaÃ±a (AEMPS):** {kb['thresholds']['spain']}
- **Reino Unido (NICE):** {kb['thresholds']['uk']}
- **OMS:** {kb['thresholds']['who']}

ğŸ’¡ **Consejo:** Un ICER por debajo del umbral sugiere que el tratamiento es coste-efectivo."""
        return response

    @classmethod
    def _explain_qaly(cls) -> str:
        kb = cls.KNOWLEDGE_BASE["qaly"]
        return f"""## QALY (AÃ±o de Vida Ajustado por Calidad)

**DefiniciÃ³n:** {kb['definition']}

**Rango:** {kb['range']}

### Ejemplos de utilidades tÃ­picas:
| Estado de salud | Utilidad |
|-----------------|----------|
| Salud perfecta | 1.00 |
| Diabetes controlada | 0.80-0.85 |
| CÃ¡ncer en remisiÃ³n | 0.70-0.80 |
| Insuficiencia cardÃ­aca | 0.50-0.70 |
| Enfermedad terminal | 0.20-0.40 |

### CÃ³mo calcular QALYs:
**QALYs = Tiempo Ã— Utilidad**

Ejemplo: 5 aÃ±os con utilidad 0.8 = 4 QALYs

ğŸ’¡ **Consejo:** Usa valores de utilidad de la literatura publicada (EQ-5D, SF-6D) para mayor credibilidad ante agencias HTA."""

    @classmethod
    def _explain_psa(cls) -> str:
        kb = cls.KNOWLEDGE_BASE["psa"]
        return f"""## PSA (AnÃ¡lisis de Sensibilidad ProbabilÃ­stico)

**DefiniciÃ³n:** {kb['definition']}

**CÃ³mo funciona:** {kb['interpretation']}

### Distribuciones recomendadas:
| Tipo de parÃ¡metro | DistribuciÃ³n |
|-------------------|--------------|
| Probabilidades | Beta |
| Costes | Gamma o Log-normal |
| Utilidades | Beta |
| Hazard ratios | Log-normal |
| Conteos | Poisson |

### Outputs principales:
- **Scatter plot:** Muestra dispersiÃ³n de resultados en plano CE
- **CEAC:** Probabilidad de ser coste-efectivo segÃºn umbral WTP
- **Intervalos de confianza:** IC 95% para ICER

ğŸ’¡ **Consejo:** Usa al menos 1,000 iteraciones. Para publicaciÃ³n, 10,000 es mÃ¡s robusto."""

    @classmethod
    def _explain_bia(cls) -> str:
        kb = cls.KNOWLEDGE_BASE["bia"]
        return f"""## BIA (AnÃ¡lisis de Impacto Presupuestario)

**DefiniciÃ³n:** {kb['definition']}

**Horizonte temporal:** {kb['time_horizon']}
**Perspectiva:** {kb['perspective']}

### Componentes clave:
1. **PoblaciÃ³n elegible:** Prevalencia Ã— DiagnÃ³stico Ã— Elegibilidad
2. **Cuotas de mercado:** Escenario actual vs. nuevo
3. **Costes por paciente:** FÃ¡rmaco + AdministraciÃ³n + MonitorizaciÃ³n
4. **Curva de adopciÃ³n:** CÃ³mo penetra el nuevo tratamiento

### Escenarios tÃ­picos:
- **Conservador:** AdopciÃ³n lenta (10-20% en 5 aÃ±os)
- **Base:** AdopciÃ³n moderada (30% en 5 aÃ±os)
- **Optimista:** AdopciÃ³n rÃ¡pida (50%+ en 5 aÃ±os)

ğŸ’¡ **Consejo:** Las agencias HTA esperan ver impacto por aÃ±o y acumulado. Incluye anÃ¡lisis de sensibilidad sobre tasa de adopciÃ³n."""

    @classmethod
    def _interpret_results_generic(cls) -> str:
        return """## GuÃ­a de InterpretaciÃ³n de Resultados

### Para AnÃ¡lisis Coste-Efectividad:
1. **Revisa el ICER:** Â¿EstÃ¡ por debajo del umbral de tu paÃ­s?
2. **Mira los QALYs:** Â¿La ganancia es clÃ­nicamente relevante?
3. **EvalÃºa la incertidumbre:** Â¿QuÃ© dice el PSA?

### Para Budget Impact:
1. **Impacto aÃ±o 1:** Â¿Es manejable?
2. **Impacto acumulado:** Â¿Sostenible a 5 aÃ±os?
3. **Pico de gasto:** Â¿CuÃ¡ndo ocurre?

### Preguntas clave:
- Â¿Los resultados son sensibles a algÃºn parÃ¡metro?
- Â¿La probabilidad de ser coste-efectivo supera 50%?
- Â¿El impacto presupuestario es asumible?

ğŸ“Š **Comparte tus resultados** y te ayudo a interpretarlos en detalle."""

    @classmethod
    def _configuration_guide(cls) -> str:
        return """## GuÃ­a de ConfiguraciÃ³n de Modelos

### Modelo Markov (3 estados):
| ParÃ¡metro | TÃ­pico | Fuente |
|-----------|--------|--------|
| Horizonte | 10-20 aÃ±os | GuÃ­as HTA |
| Tasa descuento | 3-3.5% | PaÃ­s especÃ­fico |
| TamaÃ±o cohorte | 1,000 | ConvenciÃ³n |

### Probabilidades de transiciÃ³n:
- **De ensayo clÃ­nico:** Convertir tasas a probabilidades
- **FÃ³rmula:** p = 1 - exp(-rate Ã— time)

### Costes:
- Usar **costes unitarios oficiales** (BOT, tarifas SNS)
- Incluir: fÃ¡rmaco + administraciÃ³n + monitorizaciÃ³n + eventos adversos

### Utilidades:
- Preferir **EQ-5D** (aceptado por NICE, AEMPS)
- Si no disponible, SF-6D o mapeo

ğŸ’¡ **Consejo:** Documenta TODAS las fuentes. Las agencias HTA valoran la transparencia."""

    @classmethod
    def _general_help(cls, error: str = None) -> str:
        msg = """## ğŸ‘‹ Â¡Hola! Soy tu asistente de farmacoeconomÃ­a

Puedo ayudarte con:

1. **ğŸ“Š Interpretar resultados** - Explico quÃ© significan ICER, QALYs, etc.
2. **âš™ï¸ Configurar modelos** - Te guÃ­o en los parÃ¡metros correctos
3. **ğŸ“ Generar informes** - Creo resÃºmenes ejecutivos
4. **â“ Resolver dudas** - Respondo preguntas sobre HTA

### Ejemplos de preguntas:
- "Â¿QuÃ© significa un ICER de 25,000 â‚¬/QALY?"
- "Â¿CÃ³mo configuro un anÃ¡lisis de impacto presupuestario?"
- "Â¿QuÃ© distribuciÃ³n uso para costes en el PSA?"
- "Interpreta estos resultados: [pega tus datos]"

**Escribe tu pregunta y te ayudo.**"""

        if error:
            msg += f"\n\nâš ï¸ *Nota: Funcionando en modo offline. {error}*"

        return msg


class PharmEconAssistant:
    """
    Asistente principal de farmacoeconomÃ­a

    Combina LLM externo (cuando disponible) con base de conocimiento local.
    """

    def __init__(self, config: Optional[AssistantConfig] = None):
        self.config = config or AssistantConfig()
        self.conversation_history: List[Dict] = []
        self.analysis_context: Dict = {}

        # Inicializar cliente segÃºn proveedor
        if self.config.provider == LLMProvider.OPENAI:
            self.client = OpenAIClient(self.config)
        elif self.config.provider == LLMProvider.ANTHROPIC:
            self.client = AnthropicClient(self.config)
        else:
            self.client = None

    def set_analysis_context(self, context: Dict):
        """Establecer contexto del anÃ¡lisis actual"""
        self.analysis_context = context

    def clear_history(self):
        """Limpiar historial de conversaciÃ³n"""
        self.conversation_history = []

    async def chat(self, user_message: str) -> str:
        """
        Procesar mensaje del usuario y generar respuesta

        Args:
            user_message: Mensaje del usuario

        Returns:
            Respuesta del asistente
        """
        # Construir mensajes con contexto
        messages = self._build_messages(user_message)

        # AÃ±adir a historial
        self.conversation_history.append({"role": "user", "content": user_message})

        # Obtener respuesta
        if self.client:
            response = await self.client.complete(messages)
        else:
            response = PharmacoeconomicsExpert.generate_offline_response(messages)

        # Guardar respuesta en historial
        self.conversation_history.append({"role": "assistant", "content": response})

        return response

    def _build_messages(self, user_message: str) -> List[Dict]:
        """Construir lista de mensajes con sistema y contexto"""
        messages = [
            {"role": "system", "content": self._build_system_prompt()}
        ]

        # AÃ±adir contexto del anÃ¡lisis si existe
        if self.analysis_context:
            context_msg = f"Contexto del anÃ¡lisis actual:\n```json\n{json.dumps(self.analysis_context, indent=2, ensure_ascii=False)}\n```"
            messages.append({"role": "system", "content": context_msg})

        # AÃ±adir historial reciente (Ãºltimos 10 mensajes)
        messages.extend(self.conversation_history[-10:])

        # AÃ±adir mensaje actual
        messages.append({"role": "user", "content": user_message})

        return messages

    def _build_system_prompt(self) -> str:
        """Construir prompt de sistema"""
        return f"""{PharmacoeconomicsExpert.SYSTEM_PROMPT}

InformaciÃ³n adicional:
- Idioma preferido: {self.config.language}
- Plataforma: EcoModel Hub v2.0
- MÃ³dulos disponibles: Markov, Decision Tree, BIA, PSA, Tornado, Survival Analysis, EVPI/EVPPI

Cuando interpretes resultados:
1. SÃ© especÃ­fico con los nÃºmeros
2. Compara con umbrales estÃ¡ndar
3. Destaca incertidumbres
4. Sugiere prÃ³ximos pasos

Formato de respuesta:
- Usa markdown para mejor legibilidad
- Incluye tablas cuando sea Ãºtil
- Usa emojis con moderaciÃ³n para destacar puntos clave"""

    async def interpret_results(self, results: Dict, analysis_type: str) -> str:
        """
        Interpretar resultados de un anÃ¡lisis

        Args:
            results: Resultados del anÃ¡lisis
            analysis_type: Tipo de anÃ¡lisis (markov, bia, psa, etc.)

        Returns:
            InterpretaciÃ³n en lenguaje natural
        """
        self.set_analysis_context(results)

        prompts = {
            "markov": "Interpreta estos resultados de anÃ¡lisis Markov coste-efectividad. Explica el ICER, si es coste-efectivo, y quÃ© significa para la toma de decisiones.",
            "bia": "Interpreta este anÃ¡lisis de impacto presupuestario. Explica el impacto por aÃ±o, el impacto acumulado, y si es asumible para el sistema sanitario.",
            "psa": "Interpreta estos resultados del anÃ¡lisis de sensibilidad probabilÃ­stico. Explica la incertidumbre, la probabilidad de ser coste-efectivo, y quÃ© parÃ¡metros generan mÃ¡s variabilidad.",
            "tornado": "Interpreta este diagrama tornado. Identifica los parÃ¡metros mÃ¡s influyentes y quÃ© significa para la robustez de los resultados.",
            "decision_tree": "Interpreta estos resultados del Ã¡rbol de decisiÃ³n. Explica la estrategia Ã³ptima y el valor esperado.",
            "survival": "Interpreta este anÃ¡lisis de supervivencia. Explica el ajuste del modelo, la mediana de supervivencia, y las implicaciones para el modelo econÃ³mico.",
            "voi": "Interpreta estos resultados del valor de informaciÃ³n. Explica el EVPI, quÃ© parÃ¡metros priorizar para investigaciÃ³n futura, y si vale la pena invertir en mÃ¡s estudios."
        }

        prompt = prompts.get(analysis_type, "Interpreta estos resultados y explica quÃ© significan.")

        return await self.chat(prompt)

    async def generate_executive_summary(self, all_results: Dict) -> str:
        """
        Generar resumen ejecutivo de todos los anÃ¡lisis

        Args:
            all_results: Diccionario con todos los resultados

        Returns:
            Resumen ejecutivo en formato markdown
        """
        self.set_analysis_context(all_results)

        prompt = """Genera un RESUMEN EJECUTIVO profesional de estos anÃ¡lisis farmacoeconÃ³micos.

El resumen debe incluir:
1. **ConclusiÃ³n principal** (1-2 frases)
2. **Resultados clave** (bullet points)
3. **Incertidumbre** (Â¿quÃ© tan seguros estamos?)
4. **RecomendaciÃ³n** (Â¿quÃ© deberÃ­a hacer el decisor?)
5. **Limitaciones** (Â¿quÃ© no captura el modelo?)

Formato: profesional pero accesible, apto para directivos no tÃ©cnicos.
ExtensiÃ³n: mÃ¡ximo 500 palabras."""

        return await self.chat(prompt)

    async def suggest_parameters(self, disease_area: str, treatment_type: str) -> str:
        """
        Sugerir parÃ¡metros basados en Ã¡rea terapÃ©utica

        Args:
            disease_area: Ãrea de enfermedad (oncologÃ­a, cardiovascular, etc.)
            treatment_type: Tipo de tratamiento (oral, IV, etc.)

        Returns:
            Sugerencias de parÃ¡metros
        """
        prompt = f"""Sugiere parÃ¡metros tÃ­picos para un modelo farmacoeconÃ³mico en:
- Ãrea terapÃ©utica: {disease_area}
- Tipo de tratamiento: {treatment_type}

Incluye:
1. Horizonte temporal recomendado
2. Estados del modelo Markov tÃ­picos
3. Rangos de utilidades esperados
4. Tipos de costes a incluir
5. Fuentes de datos recomendadas

Basa tus sugerencias en literatura publicada y guÃ­as HTA."""

        return await self.chat(prompt)


# Instancia global del asistente
_assistant_instance: Optional[PharmEconAssistant] = None


def get_assistant() -> PharmEconAssistant:
    """Obtener instancia del asistente (singleton)"""
    global _assistant_instance
    if _assistant_instance is None:
        _assistant_instance = PharmEconAssistant()
    return _assistant_instance


async def quick_interpret(results: Dict, analysis_type: str) -> str:
    """FunciÃ³n de conveniencia para interpretaciÃ³n rÃ¡pida"""
    assistant = get_assistant()
    return await assistant.interpret_results(results, analysis_type)
